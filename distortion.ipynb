{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace for Data Compression Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Background\n",
       "\n",
       "Video compression is based on two kinds of redundancy:\n",
       "- Spatial redundancy: Each frame (effectively an image) features 'redundancy' in pixel correlation.\n",
       "    (each pixel is likely to be similar to its immediate neighbours).\n",
       "- Temporal redundancy:\n",
       "    Most frames in a video are likely to be very similar to its immediate neighbour (predecessor and successor).\n",
       "\n",
       "A typical technique for video compression involves:\n",
       "- encoding the first frame using a still image compression method.\n",
       "- encodes several successive frames in terms of their difference from the frame before.\n",
       "\n",
       "\n",
       "## Motion Compensation\n",
       "\n",
       "Not only are successive frames generally similar,\n",
       "but more specifically, it is common for a part (or 'block') in one frame to more to a different location in the next frame,\n",
       "e.g., an object moving against a static background.\n",
       "This can be expressed in terms of the 'block's\n",
       "- previous location,\n",
       "- current location\n",
       "- boundaries (size)\n",
       "\n",
       "Motion compensation is:\n",
       "- effective if objects are just translated (moved up/down and side/side)\n",
       "- not so effective if objects are scaled (made bigger/smaller) or rotated.\n",
       "\n",
       "\n",
       "## Measuring Change\n",
       "\n",
       "In principle, the block that we're tracking can have any shape.\n",
       "In practice, we tend to limit search to equal size square blocks.\n",
       "The encoder scans the current frame block by block.\n",
       "For each block $B$ it searches the neighbouring frame for a similar block $C$.\n",
       "Finding such a block, the encoder writes the difference between its past and present locations on the output.\n",
       "This difference is of the form\n",
       "$$\n",
       "    (C_x - B_x, C_y - By) = ( \\Delta_x, \\Delta_y),\n",
       "$$\n",
       "so it is called a _motion vector_. \n",
       "\n",
       "\n",
       "## Block Search\n",
       "\n",
       "The search for matching elements is normally restricted to\n",
       "a small area (called the _search area_) around the references block $B$.\n",
       "The size of the search is defined by the maximum displacement parameters $dx$ and $dy$.\n",
       "These parameters specify the maximum horizontal and vertical distances, in pixels,\n",
       "between $B$ and any matching block in the previous frame.\n",
       "If $B$ is a square with side $b$, the search area will contain $(b + 2dx)(b + 2dy)$ pixels\n",
       "and will consist of $(2dx+1)(2dy +1)$ distinct, overlapping $b \\times b$ squares.\n",
       "The number of candidate blocks in this area is therefore proportional to $dxdy$.\n",
       "\n",
       "## Distortion measure\n",
       "\n",
       "The distortion measure selects the best match for block $B$ in the neighbouring frame.\n",
       "The difference can be measures in several ways including the following.\n",
       "\n",
       "The **Mean absolute error** (or 'mean absolute difference') calculates the \n",
       "average of the absolute differences between a pixel $B_{i,j}$ in $B$ and its counterpart $C_{i,j}$ in block $C$:\n",
       "$$\n",
       "    \\frac{1}{b^2} \\sum_{i=1}^b \\sum_{j=1}^b \\left| B_{i,j} - C_{i,j}  \\right|.\n",
       "$$\n",
       "This measure is calculated for each of the $(2dx+1)(2dy +1)$ distinct, overlapping\n",
       "$b \\times b$ candidate blocks, and the smallest distortion (say, for block $\\hat{C}$) is examined.\n",
       "If it is smaller than the _search threshold_,\n",
       "then $\\hat{C}$ is selected as the match for $B$.\n",
       "Otherwise, there is no match for $B$, and $B$ has to be encoded without motion compensation.\n",
       "\n",
       "The **mean square difference** is similar:\n",
       "$$\n",
       "    \\frac{1}{b^2} \\sum_{i=1}^b \\sum_{j=1}^b ( B_{i,j} - C_{i,j}  )^2.\n",
       "$$\n",
       "\n",
       "Finally, the **pel difference classification** (PDC) counts how many differences\n",
       "$|B_{i,j} - C_{i,j}|$ are below a given PDC parameter $p$.\n",
       "\n",
       "\n",
       "## Task\n",
       "\n",
       "- Type: Implement\n",
       "- Task:\n",
       "    - Create two fake 'frames'\n",
       "        (arrays of the same shape)\n",
       "        and chose values of\n",
       "        $B$ (position), \n",
       "        $b$ (size),\n",
       "        and the maximum displacement parameters\n",
       "        $dx$ and $dy$.\n",
       "    - Implement a function returning each of the distinct,\n",
       "        overlapping blocks for comparison and \n",
       "        confirm that there are $(2dx+1)(2dy +1)$ in total.\n",
       "    - Implement\n",
       "        'mean absolute difference' and\n",
       "        'mean square difference' distortion measures.\n",
       "    - See which of these blocks the\n",
       "        distortion measures return as most similar\n",
       "        (and whether they agree).\n",
       "- Reference implementation:\n",
       "    `video.{mean_abs_diff},{mean_sq_diff},{block_search}`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(\"./tasks/distortion.md\")  # Load the task text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Reference implementations are provided in this repo.\n",
       "- The cells below show how to access implementations relevant to this session.\n",
       "\n",
       "How to use?\n",
       "- Try the task yourself in the workspace above, and then import the reference to compare answers.\n",
       "- If you're struggling, find the function named here in the source repo. to compare the approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"./tasks/reference.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distortion\n",
    "frame_1 = np.array([[0, 1], [2, 3]])\n",
    "frame_2 = np.array([[0, 1], [2, 4]])\n",
    "video.mean_abs_diff(frame_1, frame_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block search\n",
    "ref, comp = video.make_test_array_block()\n",
    "video.block_search(ref, comp, (1, 1), (3, 3), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-dimensional logarithmic search\n",
    "video.logarithmic_search_2d_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a fake frame pair with `scikit-image`\n",
    "\n",
    "Take an image, move it, check the most direct parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = ski.data.camera()\n",
    "ski.io.imshow(camera)\n",
    "ski.io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the frame by a pixel (or more) and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = np.zeros(512)\n",
    "camera_shift = np.vstack([new_row, camera])\n",
    "camera_shift = np.delete(camera_shift, (-1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.block_search(\n",
    "    camera,  # original\n",
    "    camera_shift,  # shifted\n",
    "    (10, 10),  # The top-left position of the reference block\n",
    "    (16, 16),  # The height and width of the reference block\n",
    "    (5, 5)  # maximum displacement parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we:\n",
    "- started at (10, 10)\n",
    "- spotted the shift of (+1, 0)\n",
    "- ended at (11, 10)\n",
    "\n",
    "QED."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
