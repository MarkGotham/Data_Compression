{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace for Data Compression Tasks\n",
    "[Click here for the source repository](https://github.com/MarkGotham/Data_Compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Background\n",
       "\n",
       "Audio compression is based on human perception.\n",
       "Successful compression achieves a good compression ratio\n",
       "(small file size when compressed)\n",
       "with the result being hardly noticeably different from the original.\n",
       "This is achieved by identifying redundancy of the data as defined by how noticeable it is to human listeners.\n",
       "\n",
       "We start by observing that a healthy human's sound perception is incredible.\n",
       "We detect a sound pressure variation of only $2 \\times 10^{-5}$ Pascals rms.\n",
       "This is the reference against which sound pressure level (SPL) is measured.\n",
       "The sensation of loudness increases logarithmically with the SPL and so it is measured in deciBel,\n",
       "spanning approximately from 0 to 130 dB.\n",
       "\n",
       "At the quiet end, we can barely hear.\n",
       "At the loud end there a pain threshold.\n",
       "It is not, however, equally sensitive across this range.\n",
       "- the minimum of $2 \\times 10^{-5}$ Pascals set as the value of 0dB falls at c.5k Hz.\n",
       "- the approximate frequency range for high-quality audio is 20 Hz to 20,000 Hz (as discussed)\n",
       "- there is disproportionate effect of level reduction on the lower, 'bass' end (c.20–200Hz)\n",
       "\n",
       "\n",
       "## Critical bands\n",
       "\n",
       "As discussed, we detect sound by vibrations of the membrane in the inner ear.\n",
       "This membrane is highly - but not infinitely - sensitive.\n",
       "When one area vibrates at a given frequency, \n",
       "so nearby areas are forced to vibrate at the same frequency with an amplitude that decreases with distance.\n",
       "\n",
       "There is, therefore a finite width to the vibration envelope.\n",
       "The psychoacoustical term to describe this is **critical bandwidth**.\n",
       "\n",
       "There are many functions for expressing frequency scale in terms of perceptually equal distances.\n",
       "I.e., these models attempt to fix equal steps according to what listeners judge to be equal in distance from one another.\n",
       "[Some are listed here](https://en.wikipedia.org/wiki/Bark_scale)\n",
       "and a few are implemented in the repo\n",
       "([`audio.py`](https://github.com/MarkGotham/Data_Compression/blob/main/implementations/audio.py)).\n",
       "One of the earliest and best known is the so-called 'Bark' scale, named after Heinrich Barkhausen\n",
       "who pioneered early subjective measurements of loudness.\n",
       "\n",
       "$$\n",
       "    1 \\text{ Bark} = \\begin{cases}\n",
       "    f/100\n",
       "    &\n",
       "    \\text{if } f \\le 500Hz,\n",
       "    \\\\\n",
       "    9 + 4 \\log_2 (f/1000)\n",
       "    &\n",
       "    \\text{if } f \\geq 500Hz\n",
       "    \\end{cases}\n",
       "$$\n",
       "\n",
       "\n",
       "$$\n",
       "    \\text{Critical bandwidth} = \\begin{cases}\n",
       "    100\n",
       "    &\n",
       "    \\text{if } f \\le 500Hz,\n",
       "    \\\\\n",
       "    0.2 \\times f\n",
       "    &\n",
       "    \\text{if } f \\geq 500Hz\n",
       "    \\end{cases}\n",
       "$$\n",
       "\n",
       "\n",
       "## Task\n",
       "\n",
       "- Type: Implement\n",
       "- Task:\n",
       "    Re-create a version of\n",
       "    [this plot of critical bands from wikimedia](https://commons.wikimedia.org/wiki/File:Bark_scale.png).\n",
       "    Plot the Bark scale data\n",
       "    with either or both of:\n",
       "    - mid-frequency against bandwidth (both Hz)\n",
       "    - 'Bark' (1–24) against the corresponding frequencies,\n",
       "        using mid-frequency and \n",
       "        using 'error bars' to represent the critical bands\n",
       "        (given here as 'upper' / 'lower').\n",
       "- Bonus: add one or more lines of best fit.\n",
       "- Reference implementation:\n",
       "    `audio.plot_bark()` for one with 'error bars', or `audio.plot_bark_models()` for several forms.\n",
       "    Use the data provided in `data/bark.csv` and load it with `audio.bark_data`.\n",
       "\n",
       "\n",
       "## Also on this repository\n",
       "\n",
       "- The [`wavelength`](https://github.com/MarkGotham/Data_Compression/blob/main/wavelength.ipynb)\n",
       "notebook introduces sound in nature;\n",
       "- Then [`tonotopic`](https://github.com/MarkGotham/Data_Compression/blob/main/tonotopic.ipynb)\n",
       "takes us into the inner ear,\n",
       "- Finally, this topic (Bark) begins our account of perception beyond physiology.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(\"./tasks/bark.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Reference implementations are provided in this repo.\n",
       "- The cells below show how to access implementations relevant to this session.\n",
       "\n",
       "How to use?\n",
       "- Try the task yourself in the workspace above, and then import the reference to compare answers.\n",
       "- If you're struggling, find the function named here in the source repo. to compare the approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(\"./tasks/reference.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.bark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.plot_bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.plot_bark_models()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
